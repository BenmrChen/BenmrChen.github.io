<!DOCTYPE html><html class="appearance-auto" lang="zh-tw"><head><meta charset="UTF-8"><title>使用 Python Pandas 來抓取台股每日資訊</title><meta name="description" content="May the Force be with you"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><link rel="stylesheet" href="/style/common/jquery.fancybox.min.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="前言在 上一篇文章 裡，我們介紹了Python Pandas厲害的地方
本篇文章則是要分享 如何使用 Python Pandas 來抓取在 【台灣證券交易所】 揭示的每日股價資訊 並在使用 Pandas 存成 Dataframe 後 存到 SQLite3 這個資料庫內，以利後續分析
結構主要可以分成
第一洞: 找到資料來源這邊會以 【台灣證券交易所】 為例
第二洞: 將資料抓下來並解析成 Pandas 可讀的格式Pandas 是啥? 請見下個段落
第三洞: 使用 Pandas 存成 Dataframe存了之後試試看可否做簡單的資料篩選
第四洞: 將資料分存入 SQLite3 內這樣子之後我們就可以使用存在SQLite3 裡面的資料來做下一步處理了
預備知識在實作前有些名詞須要先了解一下 所以簡單列一下會用到.."><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Benmr's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">使用 Python Pandas 來抓取台股每日資訊</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">點擊返回頂LOB</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">首頁</a></h3><h3 class="is-inline-block"><a href="/about">關於</a></h3><h3 class="is-inline-block"><a href="/archives">文章列表</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">首頁</a></h3><h3 class="is-inline-block"><a href="/about">關於</a></h3><h3 class="is-inline-block"><a href="/archives">文章列表</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B5%90%E6%A7%8B"><span class="toc-text">結構</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%B4%9E-%E6%89%BE%E5%88%B0%E8%B3%87%E6%96%99%E4%BE%86%E6%BA%90"><span class="toc-text">第一洞: 找到資料來源</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%B4%9E-%E5%B0%87%E8%B3%87%E6%96%99%E6%8A%93%E4%B8%8B%E4%BE%86%E4%B8%A6%E8%A7%A3%E6%9E%90%E6%88%90-Pandas-%E5%8F%AF%E8%AE%80%E7%9A%84%E6%A0%BC%E5%BC%8F"><span class="toc-text">第二洞: 將資料抓下來並解析成 Pandas 可讀的格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E6%B4%9E-%E4%BD%BF%E7%94%A8-Pandas-%E5%AD%98%E6%88%90-Dataframe"><span class="toc-text">第三洞: 使用 Pandas 存成 Dataframe</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E6%B4%9E-%E5%B0%87%E8%B3%87%E6%96%99%E5%88%86%E5%AD%98%E5%85%A5-SQLite3-%E5%85%A7"><span class="toc-text">第四洞: 將資料分存入 SQLite3 內</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A0%90%E5%82%99%E7%9F%A5%E8%AD%98"><span class="toc-text">預備知識</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Pandas"><span class="toc-text">Pandas</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#requests"><span class="toc-text">requests</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#csv%E6%AA%94"><span class="toc-text">.csv檔</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%A6%E4%BD%9C"><span class="toc-text">實作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%B4%9E-%E6%89%BE%E5%88%B0%E8%B3%87%E6%96%99%E4%BE%86%E6%BA%90-1"><span class="toc-text">第一洞: 找到資料來源</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%B4%9E-%E5%B0%87%E8%B3%87%E6%96%99%E6%8A%93%E4%B8%8B%E4%BE%86%E4%B8%A6%E8%A7%A3%E6%9E%90%E6%88%90-Pandas-%E5%8F%AF%E8%AE%80%E7%9A%84%E6%A0%BC%E5%BC%8F-1"><span class="toc-text">第二洞: 將資料抓下來並解析成 Pandas 可讀的格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E6%B4%9E-%E4%BD%BF%E7%94%A8-Pandas-%E5%AD%98%E6%88%90-Dataframe-1"><span class="toc-text">第三洞: 使用 Pandas 存成 Dataframe</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E6%B4%9E-%E5%B0%87%E8%B3%87%E6%96%99%E5%88%86%E5%AD%98%E5%85%A5-SQLite3-%E5%85%A7-1"><span class="toc-text">第四洞: 將資料分存入 SQLite3 內</span></a></li></ol></li></ol></div><div class="column is-9"><header class="my-4"></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">使用 Python Pandas 來抓取台股每日資訊</h1><time class="has-text-grey" datetime="2020-02-12T04:14:03.000Z">2020-02-12</time><article class="mt-2 post-content"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 <a target="_blank" rel="noopener" href="https://growingdna.com/python-pandas-intro/">上一篇文章</a> 裡，我們介紹了Python Pandas厲害的地方</p>
<p>本篇文章則是要分享 如何使用 Python Pandas 來抓取在 <a target="_blank" rel="noopener" href="https://www.twse.com.tw/zh/">【台灣證券交易所】</a> 揭示的每日股價資訊 並在使用 Pandas 存成 Dataframe 後 存到 SQLite3 這個資料庫內，以利後續分析</p>
<h2 id="結構"><a href="#結構" class="headerlink" title="結構"></a>結構</h2><p>主要可以分成</p>
<h3 id="第一洞-找到資料來源"><a href="#第一洞-找到資料來源" class="headerlink" title="第一洞: 找到資料來源"></a>第一洞: 找到資料來源</h3><p>這邊會以 <a target="_blank" rel="noopener" href="https://www.twse.com.tw/zh/">【台灣證券交易所】</a> 為例</p>
<h3 id="第二洞-將資料抓下來並解析成-Pandas-可讀的格式"><a href="#第二洞-將資料抓下來並解析成-Pandas-可讀的格式" class="headerlink" title="第二洞: 將資料抓下來並解析成 Pandas 可讀的格式"></a>第二洞: 將資料抓下來並解析成 Pandas 可讀的格式</h3><p>Pandas 是啥? 請見下個段落</p>
<h3 id="第三洞-使用-Pandas-存成-Dataframe"><a href="#第三洞-使用-Pandas-存成-Dataframe" class="headerlink" title="第三洞: 使用 Pandas 存成 Dataframe"></a>第三洞: 使用 Pandas 存成 Dataframe</h3><p>存了之後試試看可否做簡單的資料篩選</p>
<h3 id="第四洞-將資料分存入-SQLite3-內"><a href="#第四洞-將資料分存入-SQLite3-內" class="headerlink" title="第四洞: 將資料分存入 SQLite3 內"></a>第四洞: 將資料分存入 SQLite3 內</h3><p>這樣子之後我們就可以使用存在SQLite3 裡面的資料來做下一步處理了</p>
<h2 id="預備知識"><a href="#預備知識" class="headerlink" title="預備知識"></a>預備知識</h2><p>在實作前有些名詞須要先了解一下 所以簡單列一下會用到的名字解釋</p>
<h3 id="Pandas"><a href="#Pandas" class="headerlink" title="Pandas"></a>Pandas</h3><p>可以想像成是 Windows 的 excel 用途是快速地對資料做運算並整理成一張張厲害的表格</p>
<h3 id="requests"><a href="#requests" class="headerlink" title="requests"></a>requests</h3><p>Python 常用的 package 它可以將網路上的資料給下載下來，給程式使用</p>
<h3 id="csv檔"><a href="#csv檔" class="headerlink" title=".csv檔"></a>.csv檔</h3><p><code>.csv</code>是一種檔案的格式 它可以被excel或記事本打開 (對!就是 windows 的那個記事本)</p>
<h2 id="實作"><a href="#實作" class="headerlink" title="實作"></a>實作</h2><h3 id="第一洞-找到資料來源-1"><a href="#第一洞-找到資料來源-1" class="headerlink" title="第一洞: 找到資料來源"></a>第一洞: 找到資料來源</h3><p>可以點開台灣證券交易所的網站如下 <a target="_blank" rel="noopener" href="https://www.twse.com.tw/zh/"></a><a target="_blank" rel="noopener" href="https://www.twse.com.tw/zh/">https://www.twse.com.tw/zh/</a> [step]1[&#x2F;step] 點選【交易資訊】裡的【每日收盤行情】 <img src="https://growingdna.com/wp-content/uploads/2020/02/image-1580786147438.png" alt="file"> [step]2[&#x2F;step] 在【分類】裡點選【全部(不含權證…)】 並按下查詢 <img src="https://growingdna.com/wp-content/uploads/2020/02/image-1580786163738.png" alt="file"> [step]3[&#x2F;step] 打開「開發者工具」 (以下以Chrome為例)</p>
<ul>
<li>在網頁任一處點右鍵-&gt;檢查即可 <img src="https://growingdna.com/wp-content/uploads/2020/02/image-1580786179231.png" alt="file"> [step]4[&#x2F;step] 點開【Network】分頁，這邊可以看到你在操作網頁時與server互動的情況</li>
</ul>
<p>請點選【CSV下載】 此時你可以看到右邊開發者工具多了很東西 請點選<code>MI_INDEX?</code>開頭的那個 就可看到右邊有一個 <code>Request URL</code> 這個就是你點了【CSV下載】後會發出去的 request <img src="https://growingdna.com/wp-content/uploads/2020/02/image-1580786211227.png" alt="file"> 這個 request 會回傳【每日收盤行情】的資訊回來 接著我們就是要利用這個 request 來拉股市資訊下來處理</p>
<p>[step]5[&#x2F;step] 將這個 URL 複製下來貼到網址列裡 <a target="_blank" rel="noopener" href="https://www.twse.com.tw/exchangeReport/MI_INDEX?response=csv&date=20200120&type=ALLBUT0999">https://www.twse.com.tw/exchangeReport/MI_INDEX?response&#x3D;csv&amp;date&#x3D;20200120&amp;type&#x3D;ALLBUT0999</a> 你會得到以下畫面 這樣就可以把股市資訊的<code>csv</code>檔給抓下來了 而其中的<code>【date=20200120】</code>就是你要抓的資料日期 而這也意謂著 我們可以用這個 URL 來抓任意日期的股市資訊了</p>
<h3 id="第二洞-將資料抓下來並解析成-Pandas-可讀的格式-1"><a href="#第二洞-將資料抓下來並解析成-Pandas-可讀的格式-1" class="headerlink" title="第二洞: 將資料抓下來並解析成 Pandas 可讀的格式"></a>第二洞: 將資料抓下來並解析成 Pandas 可讀的格式</h3><p>ps. 【貼心提示】以下內容請搭配 code 傳送門服用 <a target="_blank" rel="noopener" href="https://github.com/BenmrChen/Python/blob/master/Stock_data.ipynb"></a><a target="_blank" rel="noopener" href="https://github.com/BenmrChen/Python/blob/master/Stock_data.ipynb">https://github.com/BenmrChen/Python/blob/master/Stock_data.ipynb</a></p>
<p>[step]1[&#x2F;step] 使用以下程式碼來使用python把資料抓下來 並存到 response 這個變數裡</p>
<pre><code class="python">import requests
import pandas as pd
from io import StringIO
response = requests.get(&#39;http://www.twse.com.tw/exchangeReport/MI_INDEX?response=csv&amp;date=20200120&amp;type=ALLBUT0999&amp;_=1520785530355&#39;)
</code></pre>
<p>[step]2[&#x2F;step] 試試可這個抓下來的資料可否用 <code>pandas</code>直接存取</p>
<pre><code class="python">lines = pd.read_csv(StringIO(response.text))
</code></pre>
<p>結果報錯了，它說:</p>
<pre><code>ParserError: Error tokenizing data. C error: Expected 7 fields in line 193, saw 17
</code></pre>
<p>意思是在193行，程式預期有7個欄位 但實際上有17個欄位 程式就卡住報錯了</p>
<p>怎麼辦呢? 這時候我們可以打開剛剛下載下來的<code>.csv</code>檔 這才發現 原來是因為檔案的上半部和下半部的欄位不一樣多 以致會有 pandas 讀不出來的情形發生 所以接下來就是要處理一下資料 才能讓 pandas 好處理囉~</p>
<p>[step]3[&#x2F;step]</p>
<p>我們使用<code>split</code>這個 function 來為.csv檔分行(.csv是用<code>&#39;\n&#39;</code>來斷行的) 並一行一行存到<code>lines</code>變數裡 然後把第100行印出來看看是啥</p>
<pre><code class="python">lines = response.text.split(&#39;\n&#39;)
print(lines[100])
print(lines[200])
</code></pre>
<p>嗯看起來符合預期 讚! 而且我們要的資料是下面那筆 總共有17個欄位的 所以要處理的就是把不要的那個給拿掉</p>
<p>[step]4[&#x2F;step] 我們使用<code>&quot;,</code>這個符號再把剛剛存在<code>line</code>這個變數的字串給拆開 由於我們只要有17個欄位的資料 所以寫一個判斷 把有17個欄位的存到<code>newlines</code>變數裡 並簡單驗證一下 原來的<code>lines</code>變數內的資料筆數和新的<code>newlines</code>變數內的資料筆數是否有變更</p>
<pre><code class="python">newlines = []
for line in lines:
    if len(line.split(&#39;&quot;,&#39;)) == 17:
            newlines.append(line)

print(len(lines))
print(len(newlines))
</code></pre>
<p>[step]5[&#x2F;step] 接著把剛剛的<code>newlines</code>給印出來看看</p>
<pre><code class="python">print(newlines)
</code></pre>
<p>看起來是我們想要的東西沒錯!</p>
<p>[step]6[&#x2F;step] 現在的狀況是 我們有一個list，裡面有超多筆data 但為了要讓 pandas 解析 所以我們必須要讓它成為一個string 所以使用以下 code 將<code>newlines</code>變數給黏起來 並印出來看看它有多長(string長度) 也印出來看看內容對不對 最後再用<code>type</code>函式來確認是不是string</p>
<pre><code class="python">s = &#39;\r&#39;.join(newlines)
print(s)
type(s)
</code></pre>
<p>好的! 這樣子看起來就差不多了 我們可以開始準備用 pandas 來解析囉</p>
<h3 id="第三洞-使用-Pandas-存成-Dataframe-1"><a href="#第三洞-使用-Pandas-存成-Dataframe-1" class="headerlink" title="第三洞: 使用 Pandas 存成 Dataframe"></a>第三洞: 使用 Pandas 存成 Dataframe</h3><p><img src="https://growingdna.com/wp-content/uploads/2020/02/image-1580787266534.png" alt="file"></p>
<h3 id="第四洞-將資料分存入-SQLite3-內-1"><a href="#第四洞-將資料分存入-SQLite3-內-1" class="headerlink" title="第四洞: 將資料分存入 SQLite3 內"></a>第四洞: 將資料分存入 SQLite3 內</h3><p><img src="https://growingdna.com/wp-content/uploads/2020/02/image-1580787273184.png" alt="file"> 完成!</p>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/2020/02/13/php-laravel-opay-api/" title="PHP + Laravel 雞排聯盟API實作: 串接歐付寶金流API"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">上一页: PHP + Laravel 雞排聯盟API實作: 串接歐付寶金流API</span></a><a class="button is-default" href="/2020/02/06/php-laravel-chickenfillet-auth/" title="PHP + Laravel 雞排聯盟API實作: 追加會員身份驗證"><span class="has-text-weight-semibold">下一页: PHP + Laravel 雞排聯盟API實作: 追加會員身份驗證</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="Haojen/Claudia-theme-blog" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/haojen"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright ©</span><span> Benmr 2024</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/jquery-3.6.1.min.js"></script><script src="/js/jquery-fancybox.min.js"></script><script src="/js/img_zoom.js"></script><script src="/js/post.js"></script></body></html>